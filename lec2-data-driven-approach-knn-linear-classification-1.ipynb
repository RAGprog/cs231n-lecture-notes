{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS231n Winter 2016: Lecture 2\n",
    "## Topics: Data-driven approach, kNN, Linear Classification 1\n",
    "\n",
    "video:\n",
    "https://www.youtube.com/watch?v=8inugqHkfvE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8inugqHkfvE?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8inugqHkfvE?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconditions\n",
    "Used Data sets: **CIFAR-10**\n",
    "- 10 labels\n",
    "- 50,000 training images (32x32)\n",
    "- 10,000 test images\n",
    "- keras has it (`from keras.datasets import cifar10`)\n",
    "- https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10 or https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/cifar10.py - fetch for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_images, train_labels):\n",
    "    # build model\n",
    "    return model\n",
    "\n",
    "def predict(model, test_images):\n",
    "    # predict\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbour Classifier\n",
    "property\n",
    "- accuracy on training set is 100%\n",
    "- speed: \n",
    "$$\n",
    "distance_speed = width*height*num_trained_samples \n",
    "$$\n",
    "$$\n",
    "atgmin_speed = num_trained_samples\n",
    "$$\n",
    "$$\n",
    "speed = distance_speed\n",
    "$$\n",
    "- libs FLANN - fast library for aproximate NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NearestNeighbour:\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        train model with example and labels\n",
    "        \"\"\"\n",
    "        # remember all images\n",
    "        assert len(X.shape) == 4\n",
    "        assert len(y.shape) == 2\n",
    "        self.X_trained = X\n",
    "        self.y_trained = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels for items\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(X.shape) == 3:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "            \n",
    "        assert len(X.shape) == 4\n",
    "        \n",
    "        for instance in X:\n",
    "            # - manhattan distance (L1 distance)\n",
    "            distance = np.sum(np.abs(self.X_trained - instance), axis = (1,2,3))\n",
    "            min_index = np.argmin(distance)\n",
    "            yield self.y_trained[min_index][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 s, sys: 1.06 s, total: 3.62 s\n",
      "Wall time: 3.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 8, 1, 0, 4, 2, 2, 5, 0, 8]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbour().train(x_train, y_train)\n",
    "%time list(nn.predict(x_test[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN\n",
    "\n",
    "big differences to Nearest Neighbour are\n",
    "- get k-instances the most likely \n",
    "- make majority vote\n",
    "\n",
    "property:\n",
    "- for k > 1, accuracy on training set is < 100%\n",
    "- k - hyper parameter\n",
    "- in comparison to Nearest Neighbour it smoothes boundaries\n",
    "\n",
    "practice\n",
    "- never used on images\n",
    "- terrible performance on test time\n",
    "- distance metrics on level of whole images can be very unintuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNearestNeighbour:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        train model with example and labels\n",
    "        \"\"\"\n",
    "        # remember all images\n",
    "        assert len(X.shape) == 4\n",
    "        assert len(y.shape) == 2\n",
    "        self.X_trained = X\n",
    "        self.y_trained = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels for items\n",
    "        \n",
    "        it will return the most likely class, probability of each class and list of the most likely images\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(X.shape) == 3:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "            \n",
    "        assert len(X.shape) == 4\n",
    "        \n",
    "        for instance in X:\n",
    "            # - manhattan distance (L1 distance)\n",
    "            distance = np.sum(np.abs(self.X_trained - instance), axis = (1,2,3))\n",
    "            min_indexes = distance.argsort()[:self.k]\n",
    "            counts = np.bincount(self.y_trained[min_indexes].ravel())\n",
    "            yield np.argmax(counts), counts / counts.sum(), min_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 930 ms, total: 3.79 s\n",
      "Wall time: 3.8 s\n",
      "[(0,\n",
      "  array([ 0.4,  0. ,  0. ,  0. ,  0. ,  0.2,  0. ,  0. ,  0.4]),\n",
      "  array([26608, 48381,  5699, 31426,   557])),\n",
      " (1,\n",
      "  array([ 0. ,  0.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.4]),\n",
      "  array([17592, 30047, 13109, 44448, 13239])),\n",
      " (8,\n",
      "  array([ 0. ,  0.2,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.6,  0.2]),\n",
      "  array([30047,  5675, 37678,   860, 33626])),\n",
      " (0,\n",
      "  array([ 0.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.4]),\n",
      "  array([49245, 44350, 24315,   115, 24164])),\n",
      " (0,\n",
      "  array([ 0.4,  0. ,  0. ,  0.2,  0.2,  0.2]),\n",
      "  array([10296, 23874, 41484,  9413, 46812])),\n",
      " (2,\n",
      "  array([ 0.2,  0. ,  0.4,  0. ,  0.2,  0. ,  0.2]),\n",
      "  array([13752, 46902, 27651, 26976, 31536])),\n",
      " (4,\n",
      "  array([ 0. ,  0. ,  0.4,  0. ,  0.6]),\n",
      "  array([10683, 32803,  6924,   804, 11582])),\n",
      " (0,\n",
      "  array([ 0.2,  0. ,  0.2,  0. ,  0.2,  0.2,  0.2]),\n",
      "  array([32511,  7074, 15886, 23549,  7365])),\n",
      " (0,\n",
      "  array([ 0.8,  0. ,  0. ,  0. ,  0. ,  0.2]),\n",
      "  array([48350, 46116, 10397,  5665, 42241])),\n",
      " (8,\n",
      "  array([ 0. ,  0.2,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.8]),\n",
      "  array([20958,  6139, 29290, 38525, 49851]))]\n"
     ]
    }
   ],
   "source": [
    "nn = KNearestNeighbour().train(x_train, y_train)\n",
    "%time res = list(nn.predict(x_test[:10]))\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFrlJREFUeJzt3VuMZFd1xvH/qurb3DwXDxkP9iQG\nYogsFAy0LAiWRUBEDkIySJEFD8gPFoMSLAWJPFiOFBwpDxAFEA8R0RBbmIhgCBdhRVaCYyFZvBjG\nxNjGToJxhmB7LjZ294zd16paeagaqWc4a3VNXU71eH8/aTTdZ9c5Z9WuWn26zuq9t7k7IlKexqQD\nEJHJUPKLFErJL1IoJb9IoZT8IoVS8osUSskvUiglv0ihlPwihZoaZmczuwH4ItAE/tHdP5M9fvee\nPX7ZZZcNc8qx0987jpdNOoBhbfE3yIkTJ1hcXOirmwdOfjNrAn8PvA94Bvixmd3r7k9E+1x22WUc\nufOuyrZ2uz1oKJV8wHeZ/tx5vMxGn/5W50uWvD+2wjvnzw4f7vuxw/zafy3wlLs/7e5rwD3AjUMc\nT0RqNEzyXw78asP3z/S2ichFYOw3/MzssJkdNbOjiwsL4z6diPRpmOR/Fji04fsretvO4e5H3H3e\n3ed379kzxOlEZJSGSf4fA1eZ2evMbAb4MHDvaMISkXEb+G6/u7fM7Fbg3+mW+u5y959l+5gZzWYz\nOl663wXHp7v9F51BKwF13u3f8u+PC+jCoer87n4fcN8wxxCRydBf+IkUSskvUiglv0ihlPwihVLy\nixRqqLv9F8yh0+lUN2UDJqK2pKyx1Ssymxm0pDRQWbTGzsriG/g5b5HXesuXAc+jK79IoZT8IoVS\n8osUSskvUiglv0ih6r3bb/Hd3pFP73QRTBY36sFMw+y35V0EN9Ivtr7XlV+kUEp+kUIp+UUKpeQX\nKZSSX6RQSn6RQtVb6kuMo+y11Y1jkMuojTqO7Dnnr3My8Ktz4TG+Wt9TF0JXfpFCKflFCqXkFymU\nkl+kUEp+kUIp+UUKNVSpz8yOAWeANtBy9/khjjVMKBelOufpG/R4jUZ8fRgkjk5SlltfXwvbWuut\nsG3H9u1hW9TH0VySw7jY3sOjqPP/obu/MILjiEiN9Gu/SKGGTX4Hvm9mD5vZ4VEEJCL1GPbX/uvc\n/Vkz+y3gfjP7L3d/cOMDej8UDgMcOHDZkKcTkVEZ6srv7s/2/j8FfBe4tuIxR9x93t3n9+zdM8zp\nRGSEBk5+M9thZrvOfg38EfD4qAITkfEa5tf+A8B3e+WNKeCf3f3fNtvJg9FZnWTUVjIOLG6pc1Bc\nUuHJSkqnT58O25577nhyzHbYtnt39W9XM9PT4T5ZybGdxJ918VqrOsbjzz0X7nPixIn4eKurYdt1\nf/DOsO21r31t5fbppD8y2etZ50jMUZxr4OR396eBtwwdgYhMhEp9IoVS8osUSskvUiglv0ihlPwi\nhap1Ak9nsCXXon0sPVqNI6ySMCyJo9OOy0Ynk7LXwsJC2HbVVVdVbt+1a1d8rpMnw7ann346jmMx\nLlUur1SX5hYXF8N9VlZWwjZPypv/d+x/w7b5+eqBpm9605vCffbu3Ru2bdu2LWwb9ai+cZcOdeUX\nKZSSX6RQSn6RQin5RQql5Bcp1JZZrqtE2V3l66+/PmzL7gJnc+5FosEvAG984xvDtuWlpbCt1Vqv\n3P7Siy+G+2RVjFY7vtu/tBxXCaIKwrFjx8J9Tp06FZ8rec6HDh0K2/bv3x+2RRWEcS/npiu/SKGU\n/CKFUvKLFErJL1IoJb9IoZT8IoVSqW/MspJMVsqZmhrspYnOl8WRzWe3b9++sK2xL56N2aJlsn77\ninCfTlLOayeVLbdm3DZASWw1mS/wiSeeCNtarXhJsUydc/9tpCu/SKGU/CKFUvKLFErJL1IoJb9I\noZT8IoXatJ5kZncBHwBOufube9v2Ad8ArgSOATe5+0vjC7NaWiCZUPnkfIPO69ZOyl6DlA+zOLIl\nqLK2BnFbVOrLplY0i69FzUYywi27hg3QH1mZ9e1vf3scx4Bl3Unp58r/FeCG87bdBjzg7lcBD/S+\nF5GLyKbJ7+4PAucPwr4RuLv39d3AB0ccl4iM2aCf+Q+4+9llZE/QXbFXRC4iQ9/w8+4HnfDDjpkd\nNrOjZnZ08aXabwuISGDQ5D9pZgcBev+H8x65+xF3n3f3+d3JtFUiUq9Bk/9e4Obe1zcD3xtNOCJS\nl35KfV8H3g3sN7NngE8DnwG+aWa3AL8EbhpnkCXKSkOjLhsNfrxkNJ1deKm1k+2SjepLG0db8t2K\nJbtBbZr87v6RoOm9I45FRGqkv/ATKZSSX6RQSn6RQin5RQql5BcplCbwlIF1siF6g1xX0ipaMmIu\nH985UpOabHMcdOUXKZSSX6RQSn6RQin5RQql5BcplJJfpFD1lvqyaT8GqKBslfFVA1aoNrE1SkpZ\nFJY883qjr/Nsgz3nUb9X05GMfdKVX6RQSn6RQin5RQql5BcplJJfpFC13u034rueW+XO/UCSG6/Z\n88rnnhs4mpFK40/n6atuy/tjMO7ZfIcDHnQAtd7RjwYYXUAn6sovUiglv0ihlPwihVLyixRKyS9S\nKCW/SKH6Wa7rLuADwCl3f3Nv2x3Ax4Dnew+73d3vG1eQdapzcMZWKecNKitFRdW3wZ9yVs6Lr2Hp\nEmADRdFJWke8NNiYz9TPlf8rwA0V27/g7tf0/r0qEl+kJJsmv7s/CLxYQywiUqNhPvPfamaPmtld\nZrZ3ZBGJSC0GTf4vAW8ArgGOA5+LHmhmh83sqJkdXVh4acDTicioDZT87n7S3dvu3gG+DFybPPaI\nu8+7+/yePfoFQWSrGCj5zezghm8/BDw+mnBEpC79lPq+Drwb2G9mzwCfBt5tZtfQrTgcAz4+xhhr\nlZVXLuaRh9kyU5YMfRvFXHH9S0qHyci9TlJ9awwyrG/ASRkbSRnQByrcjXeOxE2T390/UrH5zhGc\nW0QmSH/hJ1IoJb9IoZT8IoVS8osUSskvUqhaJ/B0PCw5DVqKCs+VHC+ztLQUtk1PT1dun5uZieNI\nhpWlJbYk/kGe2yB9CHn86QSeg1xWkhDXVlbCtpWl1bDtkksuqdzebAx63bvwSUsBLOurcC7O7FzD\nX7d15RcplJJfpFBKfpFCKflFCqXkFymUkl+kULWW+kZt0HJeVr46efJk2HbppZdWbt82MxufKx2p\nNtpyHkAnGOK2uhqXw7Iy4Msvvxy2bd8xl7Rtq25InlanHY+KO/1SPJPc9tk4jtZKdfzebIb7TE0l\naZFMFkpSPkzH9A1S6svi6JOu/CKFUvKLFErJL1IoJb9IoZT8IoW6qO/2Z7K7q510AEa858xM9cCe\n7K5su90O25rJHefsbn90Rx9gebl6YNKJE3EVY++ePWHbi7/+ddg2M70/bGO2uq9a661wl4XFhbDt\nTHK3f2r3rrBt6Uz1+aaSvp9JqjedRrzf9Gy837ZtQfWD+D2XLUMWl036rxLpyi9SKCW/SKGU/CKF\nUvKLFErJL1IoJb9IofpZrusQ8FXgAN06whF3/6KZ7QO+AVxJd8mum9x9k2V4LVm2KCnODTLGJZsT\nMDlXczrukugn5dLpxXCf5ZV4QM3c9p1h2yvLy2HbajKfXWe9+nxry/EAnbWZuHw1l7xDGp24jLn4\nYnVp7szp0+E+S6/E8ydmr+disvpz9Eo3LH7OzUYcR7sRxzE9F5f6Wuvxax0tKdZoxp1vzerSYVYG\n/o3j9/GYFvApd78aeAfwCTO7GrgNeMDdrwIe6H0vIheJTZPf3Y+7+096X58BngQuB24E7u497G7g\ng+MKUkRG74I+85vZlcBbgYeAA+5+vNd0gu7HAhG5SPSd/Ga2E/g28El3P+eDm3f/FrXyw5CZHTaz\no2Z2NPtsJiL16iv5zWyabuJ/zd2/09t80swO9toPAqeq9nX3I+4+7+7zu/fsHUXMIjICmya/dUcd\n3Ak86e6f39B0L3Bz7+ubge+NPjwRGZd+RvW9C/go8JiZPdLbdjvwGeCbZnYL8Evgpv5OGRRfBlqC\nKt6nkZTz1tbikWXLq2thWzSP3MqZM+E+2SiwV5bikt0LC8kxW3GMe7dXj6bbNhXH0UrKgFONuB/P\nLMYf45aC57aelD6nstJWMj/eejt+PQkqX56UxMziEqY147aOr8f7eRxjNIKz3Y7f381m9byF7VYc\nw/k2TX53/yFxufS9fZ9JRLYU/YWfSKGU/CKFUvKLFErJL1IoJb9IoWqdwNNwGt7/qKPNrLeSyTE9\n/rm2mJTRTj0fTxS5PjdTuX1bsrzTVDCRJcDySjxyj3ZcsvGk1Nfw6sJMM4nRk9dkLZlwc2Upjj86\n5NxcvLRWMynPdpJS8Hon3q8dlPTyt2FSYsv2WknKee24rBtN1JlN4toOypGjHtUnIq9CSn6RQin5\nRQql5BcplJJfpFBKfpFC1b5WX4PqEkU7mQxyKZjM8oVkHbmp5KktLcfnajSqy3kAc9uq14RreDLS\nK2yBRlJSmp2Ofy43p+Ly4ex0dTFqNSnZrbXiKLP9vBPHPxOMIowmq+weMG7Kdsv3q+5HS9bqI10j\nL3mtk/fw2lrcx9GAxalkJOZA/Xv+Y/t+pIi8qij5RQql5BcplJJfpFBKfpFC1Xq33zvtcL64xTOv\nhPv9+qWFyu3ZUljNTnyndGklvvOajBEJ74pvm4p/hraC5bMAOq34Trold45nZ+KXbW2tekDQ2npy\nJzpuop0MkGom8+qtBXMhZoOBLtm5I2ybCqoYAM1BlmZLLnvB2CgAkpclXQIsm6OyE8zV105qRZ1g\n2bBsMND5dOUXKZSSX6RQSn6RQin5RQql5BcplJJfpFCblvrM7BDwVbpLcDtwxN2/aGZ3AB8Dnu89\n9HZ3vy87VrvV4qUXTla2Lbwcl4DWW9Xli2aylFRWKmslc+CdWqguK3YD2V25+dBr9sRxZMs0dZJS\nX1JGSwfbBOXDVtIfneQaMDM9G7ZZUhNrt6vPN9VMrjcWl7aayWCb3dvjGFeD/lhP5rprJRP8dZLy\nWyNZmi2rH7aCvgqqed19OsG8f/Euv6GfOn8L+JS7/8TMdgEPm9n9vbYvuPvfXcD5RGSL6GetvuPA\n8d7XZ8zsSeDycQcmIuN1QZ/5zexK4K3AQ71Nt5rZo2Z2l5ntHXFsIjJGfSe/me0Evg180t1PA18C\n3gBcQ/c3g88F+x02s6NmdvR0spS1iNSrr+Q3s2m6if81d/8OgLufdPe2d1d8+DJwbdW+7n7E3efd\nff6SXdUz4YhI/TZNfjMz4E7gSXf//IbtBzc87EPA46MPT0TGpZ+7/e8CPgo8ZmaP9LbdDnzEzK6h\nW104Bnx8swO1Wy0WX6yed6+VjB6zZvW8ep2kJGPJXGuNpIYyO5ssvRWM3lsPRioCzCRz8SUDxFhP\n5tXLlq6KK1FxHFn5bSrpq047Ll81m9XzDM7OxOdqNOIesWSexNlkFN5ssMTaWtKHLwdzRgLp5bKR\nlJ6zZbSiqq4nZcX1oO8vYFBfX3f7fwiV4yLTmr6IbG36Cz+RQin5RQql5BcplJJfpFBKfpFC1TuB\nJ067VT3B5PTs9nC/lVZ1mWd6Ki6t7En+oKg5VR0DgM/FS2HNTVV3V8Pj460nI/CSOTVZjg8ZjgID\n2DZTPbJsJpkA09txjGQj3JIJSKeaQV8NuuzWgDtGk53OJKMmzeLjrQYjTAGS6iyd5Jg2HZWy433a\n2cn6pCu/SKGU/CKFUvKLFErJL1IoJb9IoZT8IoWqtdTXaDTYsb26pNdO1jlrBmUqS0o8lpTDds3F\nEz620hJK9fk6SezLq3Ecq9nIvUZcckyG7jEdjDy0rGyUjDjLypGNZMLNmSB8TyYSzUax2Uz8mnm2\nVmKn+nlbMnnqXHI8S0qfK8l7zi2ZbDYoO3oy6afNVMfRzCqi59GVX6RQSn6RQin5RQql5BcplJJf\npFBKfpFC1VrqM4ypYGScJ6WoZjDBpCUlqk4yUm11NW5bW14K2zyoozSmqkdlAby8HK8L2EpGxe3c\nFR/TsjXhglLaenKu6ikae7IJK5PdpoLGZFBcNoCQdjspsSVlu0Zw0G3BxJ4Qxw4wk9XSklGmnaSP\no4los/KgZ53VJ135RQql5BcplJJfpFBKfpFCKflFCrXp3X4zmwMeBGZ7j/+Wu3/azF4H3ANcCjwM\nfNTd41vbAAYW3MFM7l+HA3g8GdjTTgZZBFMCAoTVCIBWMPBkaXk13GdlNe6SXTvmwrZtU8mgpaQy\n0mhW92Q2oKaRzGeXLeU1nVQdosEqU8kd7Ow1y5a7arfj/p+brh5htH0u7vukO+gk/TibLM22nlQr\noqXZsrv9K2v13O1fBd7j7m+huxz3DWb2DuCzwBfc/XeBl4Bbho5GRGqzafJ719mVKKd7/xx4D/Ct\n3va7gQ+OJUIRGYu+PvObWbO3Qu8p4H7gF8CCu5/964pngMvHE6KIjENfye/ubXe/BrgCuBb4vX5P\nYGaHzeyomR09fSZeylpE6nVBd/vdfQH4AfBOYI+Znb07dgXwbLDPEXefd/f5S3btHCpYERmdTZPf\nzF5jZnt6X28D3gc8SfeHwJ/0HnYz8L1xBSkio9fPwJ6DwN1m1qT7w+Kb7v6vZvYEcI+Z/Q3wn8Cd\nmx7J4wE87WTgSaMRlEKS8k82F597tlRTMpgimA+uHWwHmJ2JB5Ds3Ba3zSTz4zUayZJRQTkyG6zS\nSNqyeRIblsydF7yeWf9my1Nlr/V0Ev+O7dUlvWYyQCcri5IMIppNlkRLnnbclvSvW/V7J1/W7Fyb\nJr+7Pwq8tWL703Q//4vIRUh/4SdSKCW/SKGU/CKFUvKLFErJL1Ioy+bOG/nJzJ4Hftn7dj/wQm0n\njymOcymOc11scfyOu7+mnwPWmvznnNjsqLvPT+TkikNxKA792i9SKiW/SKEmmfxHJnjujRTHuRTH\nuV61cUzsM7+ITJZ+7Rcp1ESS38xuMLP/NrOnzOy2ScTQi+OYmT1mZo+Y2dEaz3uXmZ0ys8c3bNtn\nZveb2c97/++dUBx3mNmzvT55xMzeX0Mch8zsB2b2hJn9zMz+vLe91j5J4qi1T8xszsx+ZGY/7cXx\n173trzOzh3p58w2zYGhfv9y91n90J+r9BfB6YAb4KXB13XH0YjkG7J/Aea8H3gY8vmHb3wK39b6+\nDfjshOK4A/iLmvvjIPC23te7gP8Brq67T5I4au0Tuosn7ux9PQ08BLwD+Cbw4d72fwD+dJjzTOLK\nfy3wlLs/7d2pvu8BbpxAHBPj7g8CL563+Ua6E6FCTROiBnHUzt2Pu/tPel+foTtZzOXU3CdJHLXy\nrrFPmjuJ5L8c+NWG7yc5+acD3zezh83s8IRiOOuAux/vfX0CODDBWG41s0d7HwvG/vFjIzO7ku78\nEQ8xwT45Lw6ouU/qmDS39Bt+17n724A/Bj5hZtdPOiDo/uSHZAqd8foS8Aa6azQcBz5X14nNbCfw\nbeCT7n56Y1udfVIRR+194kNMmtuvSST/s8ChDd+Hk3+Om7s/2/v/FPBdJjsz0UkzOwjQ+//UJIJw\n95O9N14H+DI19YmZTdNNuK+5+3d6m2vvk6o4JtUnvXNf8KS5/ZpE8v8YuKp353IG+DBwb91BmNkO\nM9t19mvgj4DH873G6l66E6HCBCdEPZtsPR+ihj6x7sR+dwJPuvvnNzTV2idRHHX3SW2T5tZ1B/O8\nu5nvp3sn9RfAX04ohtfTrTT8FPhZnXEAX6f76+M63c9ut9Bd8/AB4OfAfwD7JhTHPwGPAY/STb6D\nNcRxHd1f6R8FHun9e3/dfZLEUWufAL9Pd1LcR+n+oPmrDe/ZHwFPAf8CzA5zHv2Fn0ihSr/hJ1Is\nJb9IoZT8IoVS8osUSskvUiglv0ihlPwihVLyixTq/wEuljszi1DioAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c7197b780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: draw test image and then a list of the most likely images (like in lecture)\n",
    "plt.imshow(x_test[0]), plt.imshow(x_train[res[0][2][2]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyper parameters\n",
    "\n",
    "use cross validation on folds and forget about test set until we will ready to make finaly estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: try cross validatino on cifar-10\n",
    "# - show graphics _accuracy by k_ and animate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
